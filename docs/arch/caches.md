# Caches

## 1. 引言

cache这个词源自于法语的*cacher*, 意思是"to hide". 对于处理器来说, cache是处理器用来存放指令和数据的地方, 对于程序员和
系统而言是隐藏的. 在很多情况下, 我们即使不知道cache的存在也能写出很庞大的程序, 但是对于cache的理解还是很有必要的. 它能够
指引我们优化代码, 甚至一些潜在的bug也是因为cache导致的.

在计算机发展的初期, 处理器的计算速率和内存访问速率大致是相同的. 目前处理器的计算频率已经有了很大的提高, 而外部总线和存储
设备的速率提升却不能跟上处理器的计算频率, 在很多ARM系统中需要在几十甚至上百个内核周期以访问内存. 当然目前片上的SRAM具有
和内核相同的速率, 但是由于其昂贵的造价, 只能少量地使用. 为了平衡处理器和存储设备的频率, 以提高CPU的利用率, 进而提高系统的
处理速度, 人们提出了cache的概念.

本质上, cache就是在内核与内存之间的一块小而快的memory, 存储的是对内存的copies. 由于cache中存储的是内存的片段, 所以cache
必须同时记录片段在内存中的地址以及相应的数据. 当内核需要访问内存时, 它将先查看cache中是否已经有目标地址的拷贝, 若有则用之.
这就引入了cache hit和cache miss的概念, 提高cache命中率是提高系统速度的一个主要手段, 会在以后进行详细的介绍.

之所以可以通过提高cahe的命中率来提高系统的速度, 是由于程序运行过程中对代码和数据的访问往往是局部的. 也就是说, 人们倾向于
复用相同的代码, 以至于短时间内访问的内存地址不会有过大的变化. 例如, 代码中的循环意味着短时间内会重复的执行相同的代码很多遍.
而对于数据的访问, 也可以通过合理地安排数据的存储空间把数据访问地址限定在一个较小的范围. 

Cache在提高系统速度的同时, 也带来了不确定性. 因为Cache只是保存了内存的片段, 而且对其的访问速度远快于对内存的速度, 所以存在
cache中的内容与内存中不同步的情况. 在多核或者有DMA机制下就可能访问到未及时更新的数据, 这就是所谓的coherency问题. 如果程序
员没有意识到这个问题, 有时就会出现bug而且很难查找原因.

本文结构安排如下:

## 2. Cache结构

在计算机科学中, 存储设备的层级结构(memory hierarchy)是指靠近处理器内核的小而快的memory和相对远离内核的大而慢的memory所形成
的好似金字塔的层级结构. 例如在PC机中, 我们有靠近CPU的DDR内存用于运行程序, 由很大但很慢的硬盘用于存放各种资料和文件; 在嵌入式
系统中我们有运行快速的片上存储还有相对慢的片外扩展. 理论上在系统的任何两级具有不同速率的存储设备之间增加一个cache都可以提高
系统的速度.

在冯诺依曼架构中, 只有一个unified cache同时处理指令和数据. 而在基于ARM处理器的系统中, 通常都有两个cache, 一个用于取指令称为
instruction cache(I-cache), 另一个用于装载或者存储数据称为data cache(D-cache). 这种cache结构被称为Harvard caches. 一般,
把直接与内核逻辑链接的cache称为一级缓存(L1), 随着SRAM的大小和速度的发展, L1的大小也在不断增加, 目前一般都是16KB或者32KB.很
多ARM系统还有一个二级缓存(L2). 这是一个比L1大很多的cache, 一般为256KB, 512KB或者是1MB, 但是相对较慢而且是unified cache. 如
下图所示:

![Typical harvard caches](/docs/images/harvard_caches.png)

